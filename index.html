<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Real-Time Face Swap</title>
  <style>
    body { margin: 0; display: flex; justify-content: center; align-items: center; height: 100vh; background: #000; }
    video, canvas { width: 100%; max-width: 400px; border-radius: 8px; }
    input { margin: 10px; }
    button { padding: 10px 20px; font-size: 16px; margin-bottom: 10px; }
  </style>
</head>
<body>

<video id="video" autoplay playsinline muted></video>
<canvas id="overlay"></canvas>
<input type="file" id="upload" accept="image/*">
<button id="startBtn">Start Camera</button>

<script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
<script>
  const video = document.getElementById('video');
  const canvas = document.getElementById('overlay');
  const ctx = canvas.getContext('2d');
  const btn = document.getElementById('startBtn');
  let swapFace = null;

  // Load uploaded face
  document.getElementById('upload').addEventListener('change', (e) => {
    const file = e.target.files[0];
    if (file) {
      const img = new Image();
      img.onload = () => { swapFace = img; };
      img.src = URL.createObjectURL(file);
    }
  });

  // Start camera
  btn.addEventListener('click', async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" }, audio: false });
      video.srcObject = stream;
      await video.play();
      btn.style.display = "none";

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      // Load models
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('./models');

      requestAnimationFrame(drawLoop);
    } catch (err) {
      alert("Camera error: " + err.message);
    }
  });

  // Draw loop
  async function drawLoop() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    if (swapFace) {
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                                       .withFaceLandmarks(true);
      detections.forEach(det => {
        const landmarks = det.landmarks;
        const nose = landmarks.getNose()[0];
        const jaw = landmarks.getJawOutline();
        const left = jaw[0];
        const right = jaw[16];

        const width = right.x - left.x;
        const height = width * (swapFace.height / swapFace.width);
        const x = left.x;
        const y = nose.y - height / 2;

        ctx.drawImage(swapFace, x, y, width, height);
      });
    }

    requestAnimationFrame(drawLoop);
  }
</script>

</body>
</html>